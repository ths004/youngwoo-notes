## Ollama 사용법

### 설치
```linux
curl -fsSL https://ollama.com/install.sh | sh
```

### 명령어
``` 
	#model library 모델을 실행
	ollama pull llama3

	#설치된 모델 list
	ollama list

	#

	#chat bot에서 종료
	/bye



```


#### Create a model : 모델파일로 부터 모델생성
```
ollama create mymodel -f ./Modelfile
```
#### Create a model : 모델파일로 부터 모델생성

```
	ollama pull llama3
```

### 용어설명
LLM 모델 저장 형식 GGML, GGUF
#### GGML 
GGML은 기계학습 분야에서 중요한 역할을 하는 텐서 라이브러리
조르지 게르가노프에 의해 개발되었으며, 크기가 큰 모델과 다양한 하드웨어 환경에서 높은 성능을 발휘
* 장점
	- 혁신적인 시작: GPT 모델용 파일 형식으로 처음 시도된 사례입니다.
	- 모델 공유 용이성: 하나의 파일로 모델을 쉽게 공유할 수 있습니다.
    - CPU 호환성: 다양한 사용자가 CPU에서도 GGML 모델을 실행할 수 있습니다.
* 단점
	- 유연성 부족: 모델에 추가적인 정보를 포함시키기 어렵습니다.
	- 호환성 문제: 새로운 기능 추가 시 기존 모델과의 호환 문제가 발생합니다.
	- 수동 조정 필요: 사용자가 설정을 자주 변경해야 하는 불편함이 있습니다.
#### GGUF
GGUF는 GGML을 이어받아 2023년 8월에 출시된 새로운 파일 형식입니다. 대형 언어 모델의 저장과 처리에서 중요한 진보를 이루었다.
* 장점
	- GGML 한계 극복: 사용자 경험을 중심으로 GGML의 단점을 개선했습니다.
	- 확장성: 새로운 기능을 추가해도 기존 모델과의 호환성을 유지합니다.
	- 안정성: 새로운 버전으로의 전환을 용이하게 합니다.
	- 다양한 모델 지원: Llama 모델을 포함하여 다양한 모델을 지원합니다.
* 단점
	- 전환 시간 소요: 기존 모델을 GGUF로 전환하는 데 시간이 필요합니다.
	- 새로운 형식 적응: 사용자와 개발자가 새로운 형식에 익숙해지는 데 시간이 필요합니다.


현재는 주로 LLM 추론에 많이 활용이 되고 있는걸로 보인다.
단일 파일이기 때문에 추론을 실행하기에 필요한 모든 정보들이 하나의 파일에 모두 담겨야한다.
크게 1) 모델의 Weight 텐서 값들과 2) 메타데이터가 Key-Value 형식으로 저장되어있다

 fp16 정밀도를 넘어서 8-bit, 6-bit, 5-bit, 4-bit, 3-bit 그리고 2-bit 양자 텐서타입까지 지원을 하고 있다.

